{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_OASIS():\n",
    "    with h5py.File('..\\..\\Datasets\\OASIS_balanced.h5', 'r') as hdf:\n",
    "\n",
    "        G1 = hdf.get('Train Data')\n",
    "        trainX = np.array(G1.get('trainX'))\n",
    "        trainY = np.array(G1.get('trainY'))\n",
    "        G2 = hdf.get('Test Data')\n",
    "        testX = np.array(G2.get('testX'))\n",
    "        testY = np.array(G2.get('testY'))\n",
    "\n",
    "        return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ADNI():\n",
    "    with h5py.File('..\\..\\Datasets\\ADNI_enhanced.h5', 'r') as hdf:\n",
    "\n",
    "        G1 = hdf.get('Train Data')\n",
    "        trainX = np.array(G1.get('x_train'))\n",
    "        trainY = np.array(G1.get('y_train'))\n",
    "        G2 = hdf.get('Test Data')\n",
    "        testX = np.array(G2.get('x_test'))\n",
    "        testY = np.array(G2.get('y_test'))\n",
    "\n",
    "        return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 176, 176) (8192,) (2560, 176, 176) (2560,)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'ADNdI'\n",
    "#dataset = 'ADsNI'\n",
    "# read the data which is also normalized.\n",
    "if dataset == 'ADNI':\n",
    "    x_train, y_train, x_test, y_test = load_ADNI()\n",
    "else:\n",
    "    x_train, y_train, x_test, y_test = load_OASIS()\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 3 is out of bounds for array of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5084\\136269960.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#x_train = np.expand_dims(x_train, axis=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#x_test = np.expand_dims(x_test, axis=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(a, repeats, axis)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \"\"\"\n\u001b[1;32m--> 479\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'repeat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 3 is out of bounds for array of dimension 3"
     ]
    }
   ],
   "source": [
    "#Dataset ready for deep learning\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_train = np.repeat(x_train, 3, axis=3)\n",
    "\n",
    "#x_test = np.expand_dims(x_test, axis=-1)\n",
    "x_test = np.repeat(x_test, 3, axis=3)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=4)\n",
    "y_test_cat = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "print(\"Test\",x_test.shape)\n",
    "print (\"Train\",x_train.shape)\n",
    "print(y_train.shape)\n",
    "print (y_train_cat.shape)\n",
    "print (y_test_cat.shape)\n",
    "#print(np.max(x_train[0])) #to ensure that the values are within the range [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print()\n",
    "epochs = 10 #hyperparameter\n",
    "num_classes=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, Dropout, MaxPooling2D, Activation, BatchNormalization\n",
    "import tensorflow as tf\n",
    "resnet_model = Sequential()\n",
    "\n",
    "\n",
    "pretrained_model= tf.keras.applications.InceptionResNetV2(include_top=False,\n",
    "                   #input_shape=(176,176,3),\n",
    "                   input_shape=(218,182,3),\n",
    "                   pooling='avg',classes=4,\n",
    "                   weights='imagenet')\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Dropout(0.5))\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(BatchNormalization())\n",
    "resnet_model.add(Dense(2048,kernel_initializer='he_uniform'))\n",
    "resnet_model.add(BatchNormalization())\n",
    "resnet_model.add(Activation('relu'))\n",
    "resnet_model.add(Dropout(0.5))\n",
    "resnet_model.add(Dense(1024,kernel_initializer='he_uniform'))\n",
    "resnet_model.add(BatchNormalization())\n",
    "resnet_model.add(Activation('relu'))\n",
    "resnet_model.add(Dropout(0.5))\n",
    "resnet_model.add(Dense(4,activation='softmax'))\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = tf.keras.metrics.AUC(name = 'acc')\n",
    "from tensorflow.keras.optimizers import Adam # optimizer hyperparameter\n",
    "resnet_model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=METRIC) #learning rate hyperparameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'best_weights.hdf5'\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'acc', \n",
    "                              mode = 'max' , \n",
    "                              patience = 15,\n",
    "                              verbose = 1)\n",
    "\n",
    "checkpoint    = ModelCheckpoint(filepath, \n",
    "                                monitor = 'acc', \n",
    "                                mode='max', \n",
    "                                save_best_only=True, \n",
    "                                verbose = 1)\n",
    "callback_list = [earlystopping, checkpoint]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "#batch_size hyperparamter.\n",
    "history=resnet_model.fit(x_train, y_train_cat, batch_size = 128, epochs = 200, verbose = 1, validation_data = (x_test, y_test_cat), callbacks=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(history.history)\n",
    "df.head()\n",
    "# losses[['acc','val_acc']].plot()\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,1,sharex=True, figsize=(10,8))\n",
    "ax[0].plot(df['loss'],label = 'Training Loss')\n",
    "ax[0].plot(df['val_loss'],label = 'Validation Loss')\n",
    "ax[1].plot(df['acc'],label = 'Training Accuracy')\n",
    "ax[1].plot(df['val_acc'],label = 'Validation Accuracy')\n",
    "ax[0].legend(loc='best',prop={'size':12})\n",
    "ax[1].legend(loc='best',prop={'size':12})\n",
    "ax[0].minorticks_on()\n",
    "ax[1].minorticks_on()\n",
    "ax[1].set_xlabel('Epochs', fontsize=12)\n",
    "ax[1].set_ylabel('Accuracy', fontsize=12)\n",
    "ax[0].set_ylabel('Loss', fontsize=12)\n",
    "ax[0].grid()\n",
    "ax[1].grid()\n",
    "plt.show()\n",
    "\n",
    "#saving the results\n",
    "df.to_csv('results.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(history.history['val_loss'])\n",
    "# print(history.history['val_acc'])\n",
    "# print(history.history['acc'])\n",
    "# print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "#%%\n",
    "prediction = resnet_model.predict_classes(x_test)\n",
    "\n",
    "mcm = multilabel_confusion_matrix(y_true=y_test, y_pred=prediction, labels=[0,1,2,3], samplewise=False)\n",
    "tn = mcm[:,0,0]\n",
    "tp = mcm[:,1,1]\n",
    "fp = mcm[:,0,1]\n",
    "fn = mcm[:,1,0]\n",
    "specificity = tn/(tn+fp)\n",
    "print(\"Specificity or TNR\", np.mean(specificity))\n",
    "\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(\"Sensitivity or TPR or Recall\", np.mean(sensitivity))\n",
    "\n",
    "print(\"FNR \", 1-np.mean(sensitivity))\n",
    "\n",
    "print(\"FPR\", 1-np.mean(specificity))\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n",
    "#%%\n",
    "# use model to predict probability that given y value is 1\n",
    "y_pred_proba = resnet_model.predict_proba(x_test)\n",
    "\n",
    "#calculate AUC of model\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "#print AUC score\n",
    "print(\"AUC =\",auc)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues', cbar=False, linewidth=0.5,linecolor=\"black\",fmt='')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
