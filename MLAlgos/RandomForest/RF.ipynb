{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_OASIS():\n",
    "     with h5py.File('..\\..\\Datasets\\OASIS_balanced.h5', 'r') as hdf:\n",
    "        G1 = hdf.get('Train Data')\n",
    "        trainX = np.array(G1.get('trainX'))\n",
    "        trainY = np.array(G1.get('trainY'))\n",
    "        G2 = hdf.get('Test Data')\n",
    "        testX = np.array(G2.get('testX'))\n",
    "        testY = np.array(G2.get('testY'))\n",
    "        return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ADNI():\n",
    "    with h5py.File('..\\..\\Datasets\\ADNI_enhanced.h5', 'r') as hdf:\n",
    "\n",
    "        G1 = hdf.get('Train Data')\n",
    "        trainX = np.array(G1.get('x_train'))\n",
    "        trainY = np.array(G1.get('y_train'))\n",
    "        G2 = hdf.get('Test Data')\n",
    "        testX = np.array(G2.get('x_test'))\n",
    "        testY = np.array(G2.get('y_test'))\n",
    "\n",
    "        return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 176, 176) (8192,) (2560, 176, 176) (2560,)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'ADfNI'\n",
    "# read the data which is also normalized.\n",
    "if dataset == 'ADNI':\n",
    "    x_train, y_train, x_test, y_test = load_ADNI()\n",
    "else:\n",
    "    x_train, y_train, x_test, y_test = load_OASIS()\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pixels = False #use this to choose between raw pixels and VGG16 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8192, 176, 176, 3)\n"
     ]
    }
   ],
   "source": [
    "# make it 3D (for VGG16)\n",
    "if (raw_pixels == False):\n",
    "    if dataset == 'ADNI':\n",
    "        x_train = np.repeat(x_train, 3, axis=3)\n",
    "        x_test = np.repeat(x_test, 3, axis=3)\n",
    "    else:\n",
    "        x_train = np.expand_dims(x_train, axis=-1)\n",
    "        x_train = np.repeat(x_train, 3, axis=3)\n",
    "        x_test = np.expand_dims(x_test, axis=-1)\n",
    "        x_test = np.repeat(x_test, 3, axis=3)\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 176, 176, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 176, 176, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 176, 176, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 88, 88, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 88, 88, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 88, 88, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 44, 44, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 44, 44, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 44, 44, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 44, 44, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if (raw_pixels  == False):\n",
    "\n",
    "    from tensorflow.keras.applications.vgg16 import VGG16\n",
    "    if dataset == 'ADNI':\n",
    "        VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(218, 182, 3))\n",
    "    else:\n",
    "        VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(176, 176, 3))\n",
    "    \n",
    "    # Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "    for layer in VGG_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    VGG_model.summary()  # Trainable parameters will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting VGG16 features\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,64,176,176] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node vgg16/block1_conv2/Relu (defined at C:\\Users\\noush\\AppData\\Local\\Temp\\ipykernel_11148\\3759891818.py:4) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_501]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11148\\3759891818.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Now, let us use features from convolutional network for KNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"extracting VGG16 features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVGG_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reshaping features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,64,176,176] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node vgg16/block1_conv2/Relu (defined at C:\\Users\\noush\\AppData\\Local\\Temp\\ipykernel_11148\\3759891818.py:4) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_501]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "if (raw_pixels == False):\n",
    "# Now, let us use features from convolutional network for KNN\n",
    "    print(\"extracting VGG16 features\")\n",
    "    feature_extractor=VGG_model.predict(x_train)\n",
    "    print(\"reshaping features\")\n",
    "    features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "    # print(feature_extractor.shape)\n",
    "    # print(features.shape)\n",
    "\n",
    "    X_Train = features #This is our X input to Logistic Regression.\n",
    "\n",
    "    #Send test data through same feature extractor process\n",
    "    X_test_feature = VGG_model.predict(x_test)\n",
    "    X_Test = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
    "    print(X_Test.shape)\n",
    "    print(X_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using raw pixels for classification:\n",
      "old shape (8192, 176, 176)\n",
      "new shape (8192, 30976)\n"
     ]
    }
   ],
   "source": [
    "#BELOW CODE IS FOR USING DIRECT PIXELS.\n",
    "if (raw_pixels != False):\n",
    "    print('using raw pixels for classification:')\n",
    "    print ('old shape',x_train.shape)\n",
    "    x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
    "    print('new shape',x_train.shape)\n",
    "    X_Train = x_train\n",
    "    X_Test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV 1/3] END ...criterion=gini, n_estimators=10;, score=0.773 total time=   6.0s\n",
      "[CV 2/3] END ...criterion=gini, n_estimators=10;, score=0.776 total time=   6.1s\n",
      "[CV 3/3] END ...criterion=gini, n_estimators=10;, score=0.786 total time=   6.4s\n",
      "[CV 1/3] END ...criterion=gini, n_estimators=50;, score=0.836 total time=  25.1s\n",
      "[CV 2/3] END ...criterion=gini, n_estimators=50;, score=0.832 total time=  21.8s\n",
      "[CV 3/3] END ...criterion=gini, n_estimators=50;, score=0.851 total time=  21.3s\n",
      "[CV 1/3] END ..criterion=gini, n_estimators=100;, score=0.847 total time=  42.9s\n",
      "[CV 2/3] END ..criterion=gini, n_estimators=100;, score=0.846 total time=  43.0s\n",
      "[CV 3/3] END ..criterion=gini, n_estimators=100;, score=0.867 total time=  42.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;], &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini'], 'n_estimators': [10, 50, 100]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a Random Forest classifier object\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "parameters = {\n",
    "                'n_estimators': [10,50,100],\n",
    "                'criterion': ['gini'],\n",
    "             }\n",
    "clf = GridSearchCV(RandomForestClassifier(),param_grid=parameters, cv=3, verbose=3, scoring='accuracy')\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "prediction = clf.predict(X_Train)\n",
    "print(\"training accuracy: \",metrics.accuracy_score(prediction, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimating accuracy\n",
      "Specificity or TNR 0.9636837086102125\n",
      "Sensitivity or TPR or Recall 0.8919602711941336\n",
      "FNR  0.10803972880586643\n",
      "FPR 0.036316291389787536\n",
      "Accuracy =  0.891015625\n",
      "AUC = 0.9798089971162506\n"
     ]
    }
   ],
   "source": [
    "prediction=clf.predict(X_Test)\n",
    "print(\"estimating accuracy\")\n",
    "#Print overall accuracy\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn import metrics\n",
    "mcm = multilabel_confusion_matrix(y_true=y_test, y_pred=prediction, labels=[0,1,2,3], samplewise=False)\n",
    "tn = mcm[:,0,0]\n",
    "tp = mcm[:,1,1]\n",
    "fp = mcm[:,0,1]\n",
    "fn = mcm[:,1,0]\n",
    "specificity = tn/(tn+fp)\n",
    "print(\"Specificity or TNR\",np.mean(specificity))\n",
    "\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(\"Sensitivity or TPR or Recall\",np.mean(sensitivity))\n",
    "\n",
    "print(\"FNR \", 1-np.mean(sensitivity))\n",
    "\n",
    "print(\"FPR\", 1-np.mean(specificity))\n",
    "\n",
    "\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n",
    "\n",
    "# use model to predict probability that given y value is 1\n",
    "y_pred_proba = clf.predict_proba(X_Test)\n",
    "\n",
    "#calculate AUC of model\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "#print AUC score\n",
    "print(\"AUC =\",auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAIOCAYAAABprwNxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+E0lEQVR4nO3dd3QU9d7H8c+mh1RI6C1IL0rvHRUE6UURRS4CIsUroDRREURBUAER9KoUUUDAflVApAoB6SgQUKSEngahJSFlnj+87OMKwQSS34Twfp2Tc8jM7OS7sGd5Z3Z21mFZliUAAABkOze7BwAAALhTEF4AAACGEF4AAACGEF4AAACGEF4AAACGEF4AAACGEF4AAACGEF4AAACGEF4AAACGeNg9QHZxOBx2jwAAAO4gGfkwoFwbXpLkU+c5u0dADpW45Q0lJPNpWbg+X0+HLiWl2T0GciA/bzdd5LGBW8BLjQAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIZ42D0Abl6R/IGaMOhBtWxQXr7envo9MkYDXl2inftPSJI6NKuiPp3qqXqFYgoN9lPdx6bql99PuuyjYL4AvfbvB9WiTjkF5PHWb0ejNOWj1fpy9a923CUYtnjRAs2bO1sx0dEqXaasRox6XjVq1rJ7LOQAly5d1Kx33tbqVT/qbFysyleoqBGjxqhylbvtHg2Gbd+2VfPnzVbEvr2KiY7Wm9PeUfN775MkJScna9aM6dr40zodP3Fc/v7+qluvgf49ZJjyFyho8+Q5E0e8blPBAb5a/f4gJaemquOQ2are/Q2Nmv5fnbuQ6Nwmj6+XNv1yRC/O/D7d/cx+ubvKlcivbs/NVa0eb+rrtXv08YTHVLVcERN3AzZavux7TZ40Uf2eHKDFn32lGjVqamD/fjp18uQ/3xi53vixL2rzpnBNeO11LfniG9Vv0FBP9eutqDNn7B4NhiUmJKhcuQoa+fyL165LTNT+iH3q23+gFi7+XG9MnaGjR49oyNMDbZj09sARr9vUsz2b6XjUOfV/ZYlzWeSpsy7bLFq2Q5JUonDedPdT9+6S+vfkL7Rt3zFJ0utzV+npRxqrWvmi2v0b/wHnZh9/NFedunRR567dJEkjRo9RePgGLVm8SM8Mfdbm6WCnxMRErfrxB019e6Zq1qotSXpq4NNas3qVli5epEH/HmLvgDCqYeMmati4yXXXBQQE6N0P5rgsGzn6BfV8pJtOnTqpwoX5Jf7vbD/idfz4cY0ZM0bNmzdXxYoVValSJTVv3lxjxozRsWPH7B4vx3qwSWXtiDiuBa89pqPLxmrT/CHq3aFOpvcTvvuIut5XVXkDfeVwONTt/qry9vTQ+h2HsmFq5BTJV64oYt9e1W/QyGV5/QYNtXvXTpumQk6Rmpqi1NRUeXl5uyz39vbWzp3bbZoKt4uLFy7I4XAoICDQ7lFyJFuPeG3YsEGtW7dW8eLF1bJlS7Vs2VKWZSkqKkpfffWVZsyYoWXLlqlhw4Y33E9SUpKSkpIMTZ0zlCqST/0619fbi9Zr8rzVqlW5hN4c1lFJV1K1cFnGnxh7jvlEH7/6mE6uHK/klFRdTryih0d+pMMnYrNxetjt7LmzSk1NVUhIiMvykJBQxcRE2zQVcgo/P3/dU7WaPvjPLJW66y6FhIRq+fffac+vv6hEyZJ2j4ccLCkpSW9Pe1MPtGkrf39/u8fJkWwNr6FDh6pv376aOnVquuuHDBmirVu33nA/EydO1Lhx47JjxBzLzc2hHRHHNfbd5ZKk3b+dVKVSBfVkl/qZCq+Xn2qlvAG+aj3oP4qNv6R2TapowWs9dV//Wdr7x+nsGh85hMPhcPnesqxrluHONGHiZL384vNqdW9Tubu7q0LFSmrdpq0iIvbZPRpyqOTkZI0ePkyWZWn0C2PtHifHsvWlxj179uipp55Kd33//v21Z8+ef9zP6NGjFR8f7/KV252OuaCIw64nue4/EqXiBYMzvI9SRUM04KFG6j9hidZuO6hffz+l12av1I6I4+rftUEWT4ycJG9wXrm7uysmJsZleVxcrEJCQm2aCjlJ8eIlNHveJwr/eYeWrVyjTxYtVUpKiooWLWb3aMiBkpOTNeq5oTpx4rhmvT+bo103YGt4FS5cWOHh4emu37RpkwoXLvyP+/H29lZgYKDLV2636ZcjKlcyv8uysiVCFXn6bDq3uFYeH09JUppluSxPTUuTmxtHPXIzTy8vVaxUWZvDN7os3xwerqrVqts0FXIi3zx5lD9/AZ2Pj1d4+AY1a97C7pGQw1yNrsjIo3rvg7kKDk7/DV2w+aXG5557Tk899ZS2b9+u+++/XwULFpTD4dDp06e1cuVKffjhh5o2bZqdI+ZYMxat15oPB2t4rxb6fNVu1a5UXE90rKfBEz9zbpM30FfFC+ZV4fx/hujVUDsTe0Fn4i7owJEoHTwWrXdGddHot79VbPxltW9aWffWKavOz8615X7BnJ69emvMqBGqVKWKqlatrs+XLtapU6fU7eHudo+GHCB840+yLCksrJSORR7V1LemKCyslNp37Gz3aDDs8uVLOhYZ6fz+xInjOrA/QoFBQcqfv4BGDHtG+yP2afrM95Saluo8TzQoKEienl52jZ1jOSzrb4c7DFu8eLGmTp2q7du3KzU1VZLk7u6umjVratiwYXrooYduar8Oh0M+dZ7LylFznNYNK2r8wNYqUzxUR07G6e1F6zX36y3O9Y89WEsfvPTwNbeb8MEPevXDlZKk0sVDNWFQG9WvGiZ/X2/9cTxG0xasc16KIrdK3PKGEpJtfejnCIsXLdC8ObMVHR2lMmXLafjI0c7LB9zJfD0dupSUZvcYtvph+TLNmP6Wzpw5raCgYN173/0a9O+hCggIsHs0W/l5u+niHfbY2Lb1Zz35RK9rlrdr31H9Bw5W2wfuu+7t3p/zkWrVrpvd4+Uofl7//GqR7eF1VXJysvN8k9DQUHl6et7S/u6E8MLNI7xwI4QX0nMnhhcyLiPhlWMuoOrp6Zmh87kAAABuV7ZfQBUAAOBOQXgBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAY4rAsy7J7iOzgcDjsHgEAANxBMpJUHgbmsE1Ccq5sSmQBX0+HfKoNsnsM5FCJu2by/IHr8vV08NjALeGlRgAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMIrzvA4kUL1LplC9Wufre6d+usHdu32T0SslmR/EGaM+FxHV/zumLD39LmT0epesXizvVj+rfRri9eUEz4mzq5brK+e2+walcp6bKPFR88o4Sd77h8zZ/U2/RdgY147kB6eGzcPA+7B0D2Wr7se02eNFFjXhyratVr6LMln2pg/3768pvvVLhIEbvHQzYIDvDV6nnDtG7r7+o4eJai4i7oruKhOnchwbnNwaNRGvr6Uh0+HiNfb089/VgL/XfWYFXpME4xZy86t5v9+Ua98u63zu8TkpKN3hfYh+cOpIfHxq3hiFcu9/FHc9WpSxd17tpNd5UurRGjx6hQ4UJasniR3aMhmzzb+34dP31W/V/+RNv2HlXkqTit3fKbDh+PcW6zePk2rfn5gI6ciFXEodMa+eYXCgrwVZWyrk+aCYlXdCb2gvPr/MVE03cHNuG5A+nhsXFrCK9cLPnKFUXs26v6DRq5LK/foKF279pp01TIbg82vVs79kVqweQndHTVRG1aNFK9OzVId3tPD3f16dxQ5y5c1q+/nXBZ93CbWjq2epK2fzZGE4d2kn8e7+weHzkAzx1ID4+NW8dLjbnY2XNnlZqaqpCQEJflISGhiomJtmkqZLdSRUPVr1tjvf3Jak2e/YNqVSmpN0d0VVJyihZ+u8W5XevGVTR/Um/l8fHU6ZjzavvUO4o9d8m5/tPvt+rIyVidiTmvymWKaPzT7XR3uaJqO+AdO+4WDOK5A+nhsXHrcnx4HTt2TGPHjtWcOXPS3SYpKUlJSUkGp7q9OBwOl+8ty7pmGXIPNzeHduyL1Nh3/itJ2n3guCqVLqwnuzV2Ca91W39T3e4TFRrsr96dG+iTyU+oSc83FP2/c7zmfhnu3HbfH6d0MDJK4QtHqlqFYtq1/7jZOwVb8NyB9PDYuHk5/qXGuLg4ffTRRzfcZuLEiQoKCnL5gpQ3OK/c3d0VExPjsjwuLlYhIaE2TYXsdjrmvCIOnXZZtv/waRUvlNdl2eXEKzp0LEZbfj2iAeMWKiU1Tb1u8JLkzohjupKcojIlCmTL3Mg5eO5Aenhs3Drbj3h98803N1x/6NChf9zH6NGjNWzYMJdlxJfk6eWlipUqa3P4Rt173/3O5ZvDw9Wsxb02TobstGnXIZUr6RpHZUsUUOSpuBveziGHvD3Tf0qoVLqwvDw9dComPkvmRM7FcwfSw2Pj1tkeXh07dpTD4ZBlWelu80+HL729veXtzUm/19OzV2+NGTVClapUUdWq1fX50sU6deqUuj3c3e7RkE1mfLJaa+Y9q+FPtNTnK3eoduUwPdGloQa/8uc7jvL4eGlk31b6bt2vOh0Tr3xBfnryoSYqWjBYX6zcIUkqVSxU3dvU0ooN+xRz9qIqli6kSUM7a2fEMW3a9c+/DOH2x3MH0sNj49bYHl6FCxfWzJkz1bFjx+uu37Vrl2rWrGl2qFzkgdZtFH/urN5/d5aio6NUpmw5zXzvfRUpUtTu0ZBNtu+L1MPPfqDxT7fX80+21pETsRo+5XN9uuzPCxympqWpfFhBPdaurkKC/RQXf1nb9h7VfU9Mdb5EmZycouZ1ymvQI83ln8dLx0+f0/INe/Tqf5YpLS39X5KQe/DcgfTw2Lg1DutGh5oMaN++vapVq6bx48dfd/3u3btVvXp1paWlZWq/DodDCcn8B4Hr8/V0yKfaILvHQA6VuGsmzx+4Ll9P/m9B+nwycDjL9iNew4cP16VLl9JdX6ZMGa1Zs8bgRAAAANnD9vBq3LjxDdf7+fmpadOmhqYBAADIPjn+chIAAAC5BeEFAABgCOEFAABgCOEFAABgCOEFAABgCOEFAABgCOEFAABgCOEFAABgCOEFAABgCOEFAABgSIY+MigyMjJTOy1RosRNDQMAAJCbZSi8wsLC5HA4MrzT1NTUmx4IAAAgt8pQeM2ZMydT4QUAAIBrZSi8/vWvf2XzGAAAALnfLZ1cn5CQoBMnTiglJSWr5gEAAMi1biq81qxZo/r16ysgIEAlS5bUL7/8IkkaNGiQvvjiiywdEAAAILfIdHitXr1aLVu2VGJiop577jmlpaU514WGhmrevHlZOR8AAECukenweumll9SmTRvt3LlTEyZMcFlXtWpV7dq1K6tmAwAAyFUydHL9X+3cuVNLly6VpGve6Zg/f35FRUVlzWQAAAC5TKaPeHl4eCg5Ofm666KiohQQEHDLQwEAAORGmQ6v2rVr6+OPP77uus8++0z169e/5aEAAAByo0y/1Dhq1Ci1atVKnTp10uOPPy6Hw6Gff/5Zc+bM0WeffaY1a9Zkx5wAAAC3PYdlWVZmb/TJJ59oyJAhiouLcy4LDg7WjBkz9Oijj2bpgDfL4XAoITnTdw13CF9Ph3yqDbJ7DORQibtm8vyB6/L15P8WpM8nA4ezbiq8pD8vnrpx40ZFRUUpNDRUDRs2lJ+f383sKlsQXrgRwgs3QnghPYQXbiQj4ZXplxqv8vX11X333XezNwcAALjj3FR4nT9/XjNnztSaNWsUGxurkJAQNW/eXAMGDFBwcHAWjwgAAJA7ZPpdjYcPH9Y999yjMWPG6Pfff5eXl5d+//13jRkzRlWrVtWhQ4eyY04AAIDbXqbD65lnnlFiYqI2btyow4cPa9OmTTp8+LA2bNigpKQkDRkyJBvGBAAAuP3d1Gc1vvrqq9dcr6tBgwaaMGGCVq9enWXDAQAA5CaZDi9vb28VL178uutKlCghb2/vWx4KAAAgN8p0eHXo0MH5WY1/t3TpUrVt2/aWhwIAAMiNMvSuxh07djj/3KNHD/Xp00fdunVTjx49VKhQIZ0+fVoLFizQtm3bNHv27GwbFgAA4HaWoQuourm5yeFwOL+/epP0lqWmpmb1nJnGBVRxI1xAFTfCBVSRHi6gihvJsguozp0791ZnAQAAuONlKLx69eqV3XMAAADkepk+uR4AAAA356Y+MiguLk4LFy5URESEEhISXNY5HA5OsAcAALiOTIdXZGSkateurcuXL+vy5csKDQ1VXFycUlNTlTdvXgUFBWXHnAAAALe9TL/UOGrUKFWuXFlnzpyRZVlatmyZLl26pBkzZsjHx0ffffdddswJAABw28t0eG3atEkDBgyQj4+PpD8vI+Hl5aVBgwapT58+Gj58eJYPCQAAkBtkOrzOnDmjwoULy83NTe7u7jp//rxzXdOmTbVhw4YsHRAAACC3yHR4FSxYUHFxcZKksLAwbdu2zbnuyJEj8vC4qfP1AQAAcr1MV1K9evW0c+dOtW/fXp07d9b48eOVlJQkLy8vTZkyRS1atMiOOQEAAG57mQ6v5557TkeOHJEkvfTSS4qIiNDYsWNlWZaaNGmiadOmZfGIAAAAuUOGPqvxn5w/f14Oh0MBAQFZMVOW4LMacSN8ViNuhM9qRHr4rEbcSEY+qzFLrlwfGBiogIAArV+/npcaAQAA0pGlHxkUHR2tdevWZeUuAQAAcg0+qxEAAMAQwgsAAMAQwgsAAMAQwgsAAMCQDF1O4p577snQzs6fP69jx44pNTX1lge7VQ6Hw+4RAADAHSQjV+jK0AVU8+XLl6GQCQkJUalSpTKySyPOXk6xewTkUHnzeHAtHqTL19Ohgn2X2j0GcqAzH3bTrqPn/3lDIB0ZCq+1a9dm8xgAAAC5H+d4AQAAGEJ4AQAAGEJ4AQAAGEJ4AQAAGEJ4AQAAGEJ4AQAAGJKhy0lcz/79+7Vu3TrFxMSoT58+KlSokE6ePKm8efPK19c3K2cEAADIFTIdXqmpqXryySc1b948WZYlh8Oh1q1bq1ChQurfv7+qV6+u8ePHZ8esAAAAt7VMv9T46quvauHChZoyZYr27Nnjcnn81q1ba/ny5Vk6IAAAQG6R6SNe8+bN04svvqhhw4Zd85mMpUqV0uHDh7NsOAAAgNwk00e8Tpw4ofr16193nY+Pjy5cuHDLQwEAAORGmQ6vAgUK6NChQ9ddd+DAARUrVuyWhwIAAMiNMh1ebdq00auvvqoTJ044lzkcDsXHx+vtt99Wu3btsnRAAACA3CLT4TV+/HilpKSoUqVK6tKlixwOh55//nlVqVJFiYmJevHFF7NjTgAAgNtepsOrYMGC2rp1qx555BFt375d7u7u2r17t1q3bq3w8HDly5cvO+YEAAC47d3UBVQLFiyo9957L6tnAQAAyNX4yCAAAABDMn3E64knnrjheofDodmzZ9/0QAAAALlVpsNr9erVcjgcLstiY2N18eJFBQcHKzg4OKtmAwAAyFUyHV5Hjhy57vLVq1dr4MCBWrp06a3OBAAAkCtl2TleLVq00ODBg/XMM89k1S4BAABylSw9ub5SpUrasmVLVu4SAAAg18jS8Fq3bp1CQ0OzcpcAAAC5RqbP8Ro/fvw1y5KSkvTLL79o2bJlGj58eJYMBgAAkNtkOrxefvnla5Z5e3srLCxM48ePJ7wAAADSkenwSktLy445AAAAcr1MneOVkJCgHj16aMOGDdk1DwAAQK6VqfDy9fXV119/zVEvAACAm5DpdzVWq1ZNe/bsyY5ZAAAAcrVMh9ekSZM0efJkrVu3LjvmAQAAyLUydHL9+vXrVaNGDfn7+2vgwIG6ePGiWrRoobx586pw4cIun93ocDi0e/fubBsYAADgdpWh8GrevLk2bdqkOnXqKCQkhIukAgAA3IQMhZdlWc4/r127NrtmAQAAyNWy9CODAAAAkL4Mh9dfz+MCAABA5mX4yvXNmzeXm9s/d5rD4VB8fPwtDQUAAJAbZTi8mjVrpvz582fnLAAAALlahsPrpZdeUp06dbJzFgAAgFyNk+sBAAAMIbwAAAAMIbwAAAAMydA5Xmlpadk9BwAAQK7HES8AAABDCC8AAABDCC8AAABDCC8AAABDCC8AAABDCC8AAABDCC8AAABDMvxZjcjZ5s1+X2tX/aijRw7J29tHd1etpsFDnlXJsFIu2x0+9IdmTn9LO7ZvlZWWplKly+i1yW+pUOEiNk0OOy1etEDz5s5WTHS0SpcpqxGjnleNmrXsHgvZ6Ll2lfRc+0ouy6LiE3XPc9+6bPNYk1IKyuOlnYfjNHrhTh04ed65Pn+gt17qeo+aVioofx8PHTx9QW9/v1/f7jhh7H4ge+z7ZYe+WfqxDv8WobNxMXru5TdUp2EzSVJKSoo+nTtLO7dsVNTpE8qTx19316ijHn2eVr7Q/M59nIuL0cfvT9cvO7YoMeGSihQrqU6P9Fa9JvfZdK9yFsIrl9i5fZu6PvyIKlWuopTUVL33znT9e0BfffrFf+Xrm0eSdPxYpJ7s/Zjad+yifgMGyd8/QIcPHZKXt7fN08MOy5d9r8mTJmrMi2NVrXoNfbbkUw3s309ffvOdChchxHOz/Sfi1e2t9c7v09Is558HP1Be/e8vq2fmbtWhMxc15MGKWjy0sRq+sEKXklIkSe/0qaNAX0/1emejYi9eUee6xfWf/vXUasIq7Tl2zvTdQRZKSkxQ2F1l1bxlO705foTLuitJiTp8cL+6PNZXYXeV1cULF/TRu29q8kvDNGnWx87tZrz+ki5fuqiR499UQFCwNqxerqmvPq9JRYqpVJkKpu9SjsNLjbnE9Fnvq22HTrqrTFmVK19BL457VadPndL+ffuc27z7znQ1aNRETw99TuUrVFLRYsXVqElT5csXYuPksMvHH81Vpy5d1LlrN91VurRGjB6jQoULacniRXaPhmyWkmYp+nyS8yv24hXnun73ltH07/fr+50ntf/kef177lb5ermrc93izm1q3RWi2asPaueRs4qMuaRp3+1X/OUrurtksA33Blmpep2G6t57oOo2bnHNujx+/nrx9Vlq0PR+FSkepnKV7lbvwcN16PcIxUSddm73275f1brDwypToYoKFi6mLo/2lZ9fgA7/vt/kXcmxCK9c6uLFC5KkwKAgSX9+7FP4T+tUomSY/j2gnx5o3khPPPaw1q3+0c4xYZPkK1cUsW+v6jdo5LK8foOG2r1rp01TwZS7Cvhr15QHtWVia73Xr65KhPpJkkqE+qlgsK/W7j3j3PZKSpo2/Raj2qX//xe0nw/GqEPt4grO4ymHQ+pQu5i8PdwVfiDa+H2BvS5fuiiHw6E8fv7OZRWqVFP4upW6eD5eaWlp2rhmhZKTr6hSVU5jkHJIeCUkJGjDhg3a95ejM1clJiZq/vz5N7x9UlKSzp8/7/J1J7MsS9PfnKyq1WuodJmykqSzcbG6fPmy5s/5UPUbNNLb736gpi3u08hnn9GObVttnhimnT13VqmpqQoJcT3aGRISqpgY/vPMzXYcjtPTc7aq+7Sf9Oz87SoQ5KNvRzVXXj8vFQjykSRFn090uU30+UTl/986Ser//ma5uzm0f3oHRc7qrCmP1VTvWeE6Gn3J6H2Bva5cSdLCD99RwxYPuITX0BcmKjU1VU90uVePtqmv96e9puEvT1GhIsVsnDbnsD28fvvtN1WsWFFNmjTR3XffrWbNmunUqVPO9fHx8erdu/cN9zFx4kQFBQW5fN3JpkycoIO/HdArk95wLrt6DkeTZi30SM9eKlehono90U+NmjTTF58ttmtU2MzhcLh8b1nWNcuQu6zec1rf7Tih/SfO66eIKD329gZJ0kMNSjq3sf52G4ck6y8LR3WsouA8Xur65nq1enWV/vPjb/rgqXqqUDQw++8AcoSUlBRNe/V5WVaa+j490mXdp3Nn6dLF83rx9VmaOPNjte36qN56ZZQiDx+0adqcxfbwGjlypO6++25FRUXpwIEDCgwMVMOGDRUZGZnhfYwePVrx8fEuX3eqNyZN0E/r1mjWh/NUsGAh5/LgvMFy9/BQqdKlXbYPK3WXzvwldHFnyBucV+7u7oqJiXFZHhcXq5CQUJumgh0uX0lVxIl43VXAX1Hxfx7pKhDo47JNaKCPYv53FKxkfj/1aVFGQz/apg37o7TveLze/G+Edh85q97NS1+zf+Q+KSkpmjphlKJPn9QLr890Odp1+uRxLf96iQY8+5LurlFHYaXLqVvPJ1W6XCUt/3qJjVPnHLaHV3h4uF577TWFhoaqTJky+uabb9S6dWs1btxYhw4dytA+vL29FRgY6PJ1p7EsS1MmTtDaVT9q5vtzVKSo6yFdT08vVapURUePHHZZHnn0CJeSuAN5enmpYqXK2hy+0WX55vBwVa1W3aapYAcvDzeVLRygM/GJioy5pDPnEtS0UgHnek93h+qXC9XWP2IlSb5e7pJc3wkpSamWJTeOluZ6V6Pr9IlIvfj6LAUEBrusv5L0Z6A7HK554ebmJsv6+7HUO5Ptl5NISEiQh4frGDNnzpSbm5uaNm2qhQsX2jTZ7WXKa69oxbLvNGXaO/Lz81Ps/87T8fMPkI/Pn7+9PvavJzRmxDBVr1FLNWvX0ebwDdqwfq1mfTjPxslhl569emvMqBGqVKWKqlatrs+XLtapU6fU7eHudo+GbDS26z364ZeTOhF3WSEBPhr6YAUF+HhqSfhRSdIHqw7q320q6FDURR0+c1H/blNBCVdS9cXPxyRJB09f0KEzFzS5Zw2NX/qL4i5dUetqRdS0YkH1nLHxRj8at4HEhMs6feKY8/uo0yd05OAB+QcGKW9IqN4aP0KHDx7QyFemKi0tVefi/jxq7h8QJA9PTxUpHqZCRYrrg+mvqeeTz8g/MFhbN67VLzt+1shXptp1t3IUh2VzgtapU0dPP/20evbsec26wYMHa8GCBTp//rxSU1MztV+Hw6Gzl1Oyaswcr261Stdd/uK4V9W2Qyfn99989bk+mv2BoqPOqETJMPUbMFhNm99raswcI28eDyUk89vX4kULNG/ObEVHR6lM2XIaPnK0ataqbfdYtvP1dKhg36V2j5Et3utXV/XKhSqfv7diLyRp+6FYTf56r347dcG5zXPtKqlnk1IK8vPSzkN/XkB1/18uoFqqgL/GdK6iumVD5eftocNRF/XuD7/ps80ZP0XkdnXmw27adTT3voFr7+5tGvfcU9csb3p/W3V7/EkN7tn+urcb+8Z7qvy/dy2eOh6pBbNn6MCe3UpMvKxCRYqrXdfH1OT+B7N19pygaomAf9zG9vCaOHGifvrpJ33//ffXXT9w4EC99957SktLy9R+77TwQuYQXriR3BxeuDW5Pbxwa26L8MouhBduhPDCjRBeSA/hhRvJSHjZfnI9AADAnYLwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMITwAgAAMMRhWZZl9xDZweFw2D0CAAC4g2QkqTwMzGGb8wmpdo+AHCrQ110Jybnydw5kAV9Phw5GXbZ7DORAZQrkUUivRXaPgdsYLzUCAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAY4mH3AMg6O7Zv1cfz5igiYq9ioqP1xtQZatbiPuf62NgYzZj2pjZv2qgLFy6oRo1aGj5qjEqUDLNvaNhq8aIFmjd3tmKio1W6TFmNGPW8atSsZfdYMCg1JUWfzHlPa1d+r7OxscoXEqr72rRX91795Ob25+/mb736on5c9l+X25WvdLemvv+xHSMjG43oWEUjOlZxWXYmPkGVn/laHu4OPd/5Ht13T2GVLOCvC5eTtW7fab2ydLdOn0t0bu/l4aZx3aupc92S8vFy10/7zmj4/G06dTbB9N3JkQivXCQhIUFly5dXuw6dNOLZZ1zWWZal54YMloeHh96cNlN+/v5aMH+eBvZ/Qku/+Fa+efLYNDXssnzZ95o8aaLGvDhW1arX0GdLPtXA/v305TffqXCRInaPB0OWLpirZV9/pmFjxqtkqdL6ff8+TX1trPL4+avjQ486t6tZt6GGPj/O+b2np6cd48KAiOPn1GXKWuf3qWmWJMnXy0P3lMyrN7/Zq73HzinIz0uv9qiuT55povvG/eDc/tUe1dWqWlH1ezdcZy8maXz36lo4tInuHfuD0izL9N3JcQivXKRhoyZq2KjJdddFHj2iX3/ZrcWff6PSZcpKkkaNeUktmzfUiuXfqWPnbiZHRQ7w8Udz1alLF3Xu+ue//YjRYxQevkFLFi/SM0OftXk6mBKx9xfVa9RMdRr8+dxRsHBRrf1xuX4/sM9lO08vT+ULCbVjRBiWkmYpKj7xmuUXEpLV9Y21LstGf7JDK8e2VNF8eXQi7rICfD31aJO7NPD9zVq/74wkacD7m7T7rfZqWrmg1uw5beIu5Gic43WHSE5OliR5e3s7l7m7u8vD01O7du6wayzYJPnKFUXs26v6DRq5LK/foKF279pp01SwQ+W7q2vX9p91PPKoJOnQ7we075edql3P9bHx685teqRtc/Xt3l7TXx+nc2fj7BgXBtxVMEB7pnbQ9ilt9cGA+iqZ3y/dbQN8PZWWZin+8hVJUrWwvPLycHcJrNPnEhVxPF51yhDuEke87hhhYaVUuEgRvfP2VD3/4svy9fXVgvkfKTYmRjHR0XaPB8POnjur1NRUhYSEuCwPCQlVTAyPhztJt8d669Kli+r/aEe5ubkrLS1Vjz85WM3ub+3cpma9RmrU/H4VKFREZ06e0McfztTof/fT27MXydPLy8bpkdW2/xGrQR9s1h+nLyh/oI+ebV9Z379wnxo9v0xnL11x2dbb000vdauqzzcf1cXEFElSgSBfJSWnKv5yssu20eeTVCDIx9j9yMlyRHhFRERo8+bNql+/vipUqKD9+/dr+vTpSkpK0mOPPaYWLVrc8PZJSUlKSkoyNO3tycPTU5PffFuvvPyCWjSuJ3d3d9WpW18NGjW2ezTYyOFwuHxvWdY1y5C7rV+1Qmt++E4jxk5UiVKldej3A3r/7SkKCc2v+1q3lyQ1vbeVc/uwu8qobIVK+lfX1tqy6Sc1bHqvXaMjG6z69ZTzzxGK17aDMdo6pa26Nyqld1cccK7zcHfogwEN5OaQhs/f9o/7dUji7K4/2R5ey5cvV4cOHeTv76/Lly/ryy+/1OOPP66qVavKsiy1atVKK1asuGF8TZw4UePGjUt3Pf5UsVJlLVzypS5euKDk5GTlzZdPvR59WJUqV7Z7NBiWNziv3N3dFRMT47I8Li5WIZzHc0eZPWuquj3aW03ve0CSVKp0WUWdPqUlH89xhtff5QvNrwKFCuvksUiTo8IGl6+kKuJYvO4q6O9c5uHu0OyBDVUi1E+dXl/jPNolSVHxCfL2dFdQHk+Xo16hgd7aetD1+eZOZfs5XuPHj9fw4cMVGxuruXPnqkePHurXr59WrlypH3/8USNGjNCkSZNuuI/Ro0crPj7e5Qvp8w8IUN58+RR59Igi9u1R02b8xnqn8fTyUsVKlbU5fKPL8s3h4aparbpNU8EOSYmJzstGXOXm7qa0tLR0b3M+/pyio85wsv0dwMvDTeWKBOrM/y4XcTW67irory5T1l7z8uOuI2d1JSVVzSoXci4rGOSjisWCtIXwkpQDjnjt3btX8+fPlyQ99NBD6tmzp7p06eJc/8gjj2j27Nk33Ie3t7fLSeN3qsuXL+lY5P//BnrixHEd2B+hoKAgFSpcRD/+sFzBefOpUOHCOvj7b3pz8mtq2vxe1WvQ0MapYZeevXprzKgRqlSliqpWra7Ply7WqVOn1O3h7naPBoPqNmyiT+d/qPwFC6lkqdL647cD+nLxJ2rZpoMkKeHyZS2Y854aNrtX+UJCdebUSX30/gwFBgWrftMbnwaC28+4h6tpxa4TOh57WaGB3nq2fWUF+Hrq042H5e7m0NxBDXVPyXzqMW293N0czvO2zl68ouTUNF1ISNaC9Yc0vnt1xV28onOXkjSue3XtOx6vdXvP2Hzvcgbbw+uv3Nzc5OPjo+DgYOeygIAAjmBl0L69e/VU317O76e+8bokqW37jnr5lYmKiY7W1DdeV2xsrELzh+rBth3Ut/8Au8aFzR5o3Ubx587q/XdnKTo6SmXKltPM995XkSJF7R4NBj01dJQ+/mCmZr45UfFn45QvNL9at++iHr37S/rz6NeRQ79r1fL/6tLFC8obkl9Va9TSqHGTlSdP+u92w+2pSD5fvf9UA+UL8FLshSRt+yNWrV5ZqeOxl1U81E+taxSTJK175QGX23WYtFob90dJkl5YtFMpaZZmD2ogH093/RRxRoOn/cw1vP7HYVn2/k1UrVpVr7/+uh544M9/xD179qhChQry8PizCTds2KDHH39chw4dytR+HQ6HziekZvm8yB0Cfd2VkMyTAK7P19Ohg1GX7R4DOVCZAnkU0muR3WMgh4qZ98+vGNh+xGvAgAFKTf3/QKpSxfWjCpYtW/aP72oEAAC4Hdh+xCu7cMQLN8IRL9wIR7yQHo544UYycsTL9nc1AgAA3CkILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMILwAAAEMclmVZdg+B7JWUlKSJEydq9OjR8vb2tnsc5DA8PpAeHhu4ER4fN4fwugOcP39eQUFBio+PV2BgoN3jIIfh8YH08NjAjfD4uDm81AgAAGAI4QUAAGAI4QUAAGAI4XUH8Pb21tixYzn5EdfF4wPp4bGBG+HxcXM4uR4AAMAQjngBAAAYQngBAAAYQngBAAAYQngBAAAYQnjdAWbNmqVSpUrJx8dHNWvW1E8//WT3SMgB1q9fr3bt2qlIkSJyOBz66quv7B4JOcTEiRNVu3ZtBQQEqECBAurYsaMOHDhg91jIId59913dc889CgwMVGBgoOrXr69ly5bZPdZtg/DK5RYvXqwhQ4ZozJgx2rlzpxo3bqzWrVsrMjLS7tFgs0uXLqlq1ap655137B4FOcy6des0aNAgbd68WStXrlRKSopatmypS5cu2T0acoBixYpp0qRJ2rZtm7Zt26YWLVqoQ4cO2rt3r92j3Ra4nEQuV7duXdWoUUPvvvuuc1nFihXVsWNHTZw40cbJkJM4HA59+eWX6tixo92jIAeKjo5WgQIFtG7dOjVp0sTucZAD5cuXT1OmTFGfPn3sHiXH44hXLnblyhVt375dLVu2dFnesmVLhYeH2zQVgNtNfHy8pD//cwX+KjU1VZ9++qkuXbqk+vXr2z3ObcHD7gGQfWJiYpSamqqCBQu6LC9YsKBOnz5t01QAbieWZWnYsGFq1KiRqlSpYvc4yCF+/fVX1a9fX4mJifL399eXX36pSpUq2T3WbYHwugM4HA6X7y3LumYZAFzP4MGD9csvv2jDhg12j4IcpHz58tq1a5fOnTunzz//XL169dK6deuIrwwgvHKx0NBQubu7X3N0Kyoq6pqjYADwd08//bS++eYbrV+/XsWKFbN7HOQgXl5eKlOmjCSpVq1a2rp1q6ZPn67//Oc/Nk+W83GOVy7m5eWlmjVrauXKlS7LV65cqQYNGtg0FYCczrIsDR48WF988YVWr16tUqVK2T0ScjjLspSUlGT3GLcFjnjlcsOGDVPPnj1Vq1Yt1a9fX++//74iIyP11FNP2T0abHbx4kUdPHjQ+f3hw4e1a9cu5cuXTyVKlLBxMtht0KBBWrhwob7++msFBAQ4j5oHBQXJ19fX5ulgt+eff16tW7dW8eLFdeHCBX366adau3atli9fbvdotwUuJ3EHmDVrliZPnqxTp06pSpUqmjp1Km8Jh9auXavmzZtfs7xXr16aN2+e+YGQY6R3DujcuXP1r3/9y+wwyHH69OmjVatW6dSpUwoKCtI999yjkSNH6v7777d7tNsC4QUAAGAI53gBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBAAAYQngBuMa8efPkcDicXx4eHipWrJh69+6tEydOGJkhLCzM5WKda9eulcPh0Nq1azO1n/DwcL388ss6d+5cls4nSf/6178UFhb2j9s1a9ZMVapUyZKfefXfZtu2bVmyv7/u88iRI1m2TwDXR3gBSNfcuXO1adMmrVy5Uv369dOiRYvUuHFjXbp0yfgsNWrU0KZNm1SjRo1M3S48PFzjxo3LlvACgMzisxoBpKtKlSqqVauWJKl58+ZKTU3VK6+8oq+++kqPPvrodW9z+fJl5cmTJ8tnCQwMVL169bJ8vwBgEke8AGTY1fA5evSopD9favP399evv/6qli1bKiAgQPfee68k6cqVK5owYYIqVKggb29v5c+fX71791Z0dLTLPpOTkzVixAgVKlRIefLkUaNGjbRly5ZrfnZ6LzX+/PPPateunUJCQuTj46PSpUtryJAhkqSXX35Zw4cPlySVKlXK+dLpX/exePFi1a9fX35+fvL391erVq20c+fOa37+vHnzVL58eXl7e6tixYqaP3/+Tf0dpmfbtm3q3r27wsLC5Ovrq7CwMD3yyCPOv+u/O3v2rHr37q18+fLJz89P7dq106FDh67Z7scff9S9996rwMBA5cmTRw0bNtSqVauydHYAGUd4AciwgwcPSpLy58/vXHblyhW1b99eLVq00Ndff61x48YpLS1NHTp00KRJk9SjRw999913mjRpklauXKlmzZopISHBeft+/frpjTfe0OOPP66vv/5aXbp0UefOnXX27Nl/nGfFihVq3LixIiMj9dZbb2nZsmV64YUXdObMGUlS37599fTTT0uSvvjiC23atMnl5crXXntNjzzyiCpVqqQlS5bo448/1oULF9S4cWPt27fP+XPmzZun3r17q2LFivr888/1wgsv6JVXXtHq1atv/S/1f44cOaLy5ctr2rRpWrFihV5//XWdOnVKtWvXVkxMzDXb9+nTR25ublq4cKGmTZumLVu2qFmzZi4vqX7yySdq2bKlAgMD9dFHH2nJkiXKly+fWrVqRXwBdrEA4G/mzp1rSbI2b95sJScnWxcuXLC+/fZbK3/+/FZAQIB1+vRpy7Isq1evXpYka86cOS63X7RokSXJ+vzzz12Wb9261ZJkzZo1y7Isy4qIiLAkWUOHDnXZbsGCBZYkq1evXs5la9assSRZa9ascS4rXbq0Vbp0aSshISHd+zJlyhRLknX48GGX5ZGRkZaHh4f19NNPuyy/cOGCVahQIeuhhx6yLMuyUlNTrSJFilg1atSw0tLSnNsdOXLE8vT0tEqWLJnuz76qadOmVuXKlf9xu79KSUmxLl68aPn5+VnTp093Lr/6b9OpUyeX7Tdu3GhJsiZMmGBZlmVdunTJypcvn9WuXTuX7VJTU62qVataderUuWaff/87ApD1OOIFIF316tWTp6enAgIC1LZtWxUqVEjLli1TwYIFXbbr0qWLy/fffvutgoOD1a5dO6WkpDi/qlWrpkKFCjlf6luzZo0kXXO+2EMPPSQPjxufgvrbb7/pjz/+UJ8+feTj45Pp+7ZixQqlpKTo8ccfd5nRx8dHTZs2dc544MABnTx5Uj169JDD4XDevmTJkmrQoEGmf256Ll68qJEjR6pMmTLy8PCQh4eH/P39denSJUVERFyz/d//zho0aKCSJUs6/07Dw8MVFxenXr16udy/tLQ0PfDAA9q6dastb5IA7nScXA8gXfPnz1fFihXl4eGhggULqnDhwtdskydPHgUGBrosO3PmjM6dOycvL6/r7vfqS2exsbGSpEKFCrms9/DwUEhIyA1nu3quWLFixTJ2Z/7m6suRtWvXvu56Nze3G854dVlWXYKhR48eWrVqlV588UXVrl1bgYGBcjgcatOmjctLs3/92ddbdnXeq/eva9eu6f7MuLg4+fn5Zcn8ADKG8AKQrooVKzrf1Zievx4Fuio0NFQhISFavnz5dW8TEBAgSc64On36tIoWLepcn5KS4gyI9Fw9z+z48eM33C49oaGhkqTPPvtMJUuWTHe7v874d9dbdjPi4+P17bffauzYsRo1apRzeVJSkuLi4q57m/TmKVOmjKT/v38zZsxI992gfz9yCSD7EV4Aslzbtm316aefKjU1VXXr1k13u2bNmkmSFixYoJo1azqXL1myRCkpKTf8GeXKlVPp0qU1Z84cDRs2TN7e3tfd7uryvx81atWqlTw8PPTHH39c81LpX5UvX16FCxfWokWLNGzYMGdoHj16VOHh4SpSpMgN58wIh8Mhy7KuuQ8ffvihUlNTr3ubBQsWuMwdHh6uo0ePqm/fvpKkhg0bKjg4WPv27dPgwYNveUYAWYPwApDlunfvrgULFqhNmzZ65plnVKdOHXl6eur48eNas2aNOnTooE6dOqlixYp67LHHNG3aNHl6euq+++7Tnj179MYbb1zz8uX1zJw5U+3atVO9evU0dOhQlShRQpGRkVqxYoUWLFggSbr77rslSdOnT1evXr3k6emp8uXLKywsTOPHj9eYMWN06NAhPfDAA8qbN6/OnDmjLVu2yM/PT+PGjZObm5teeeUV9e3bV506dVK/fv107tw5vfzyy9d9uS8958+f12effXbN8vz586tp06Zq0qSJpkyZotDQUIWFhWndunWaPXu2goODr7u/bdu2qW/fvurWrZuOHTumMWPGqGjRoho4cKAkyd/fXzNmzFCvXr0UFxenrl27qkCBAoqOjtbu3bsVHR2td999N8PzA8gidp/dDyDnufout61bt95wu169ell+fn7XXZecnGy98cYbVtWqVS0fHx/L39/fqlChgtW/f3/r999/d26XlJRkPfvss1aBAgUsHx8fq169etamTZuskiVL/uO7Gi3LsjZt2mS1bt3aCgoKsry9va3SpUtf8y7J0aNHW0WKFLHc3Nyu2cdXX31lNW/e3AoMDLS8vb2tkiVLWl27drV+/PFHl318+OGHVtmyZS0vLy+rXLly1pw5c6xevXpl+F2Nkq771bRpU8uyLOv48eNWly5drLx581oBAQHWAw88YO3Zs+eav4er/zY//PCD1bNnTys4ONjy9fW12rRp4/L3etW6deusBx980MqXL5/l6elpFS1a1HrwwQetpUuXXrNP3tUIZD+HZVmWTc0HAABwR+FyEgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIYQXgAAAIb8H1G+iMC8dhzbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues', cbar=False, linewidth=0.5,linecolor=\"black\",fmt='')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "plt.savefig(\"CM-RF-ADNI-RAWPIXELS.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3803\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3804\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'learning_rate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18920\\1949338591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(df.columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best parameters\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best scores\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3804\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3805\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3807\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noush\\anaconda3\\envs\\tf2.5\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3804\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3805\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3806\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3807\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'learning_rate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "#print(df.columns)\n",
    "df['learning_rate']\n",
    "print(\"best parameters\",clf.best_params_)\n",
    "print(\"best scores\",clf.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38ee993d2b4f8eb633c0370d16521afbe82c41091b422041d03fbb1050a8fa9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
